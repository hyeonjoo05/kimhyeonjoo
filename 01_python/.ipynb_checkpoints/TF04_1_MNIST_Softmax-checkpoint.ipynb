{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중요한 역할은 아닌데 같은 랜덤으로 나오도록하는거? 777은 아무숫자나 해도 욈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100 #전체 데이터를 50번 학습하겠다\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784개의 점들이 있고 10개의 나오는 결과가 있어 \n",
    "각 점마다 10개씩의 선이 방출\n",
    "7840개의 선이 연결선이 생긴다 \n",
    "7이란 숫자가 적힌 그림이 있으면 흰색부분은 쓰지 않는 부위로 판단 0, 1이면 칠해진 영역 이렇게 점차 오차를 줄여나가는 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b, 고정해주는 역할??? 처음애는 랜더으로 아무값을 눻고  가설을 새운다 x가 들어와서 w선의 갯수 둘을 곱하고 b를 더해라 \n",
    "에러는 어떻게 정의할까 내가 세운 가설이랑 레이블을 뺴라  옵티마이즈에게 오차좀 줄려죠 부ㅌㄱ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\이유경\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 30.301753242\n",
      "Epoch: 0002 cost = 13.651443684\n",
      "Epoch: 0003 cost = 8.683834970\n",
      "Epoch: 0004 cost = 6.189706029\n",
      "Epoch: 0005 cost = 4.719171484\n",
      "Epoch: 0006 cost = 3.747886514\n",
      "Epoch: 0007 cost = 3.053896522\n",
      "Epoch: 0008 cost = 2.518704728\n",
      "Epoch: 0009 cost = 2.114380431\n",
      "Epoch: 0010 cost = 1.781753840\n",
      "Epoch: 0011 cost = 1.509917003\n",
      "Epoch: 0012 cost = 1.284388731\n",
      "Epoch: 0013 cost = 1.097028612\n",
      "Epoch: 0014 cost = 0.933608138\n",
      "Epoch: 0015 cost = 0.797004729\n",
      "Epoch: 0016 cost = 0.678665671\n",
      "Epoch: 0017 cost = 0.578840883\n",
      "Epoch: 0018 cost = 0.494206692\n",
      "Epoch: 0019 cost = 0.421074043\n",
      "Epoch: 0020 cost = 0.360129184\n",
      "Epoch: 0021 cost = 0.306333225\n",
      "Epoch: 0022 cost = 0.260521119\n",
      "Epoch: 0023 cost = 0.223681994\n",
      "Epoch: 0024 cost = 0.191932058\n",
      "Epoch: 0025 cost = 0.164674941\n",
      "Epoch: 0026 cost = 0.142096733\n",
      "Epoch: 0027 cost = 0.122863857\n",
      "Epoch: 0028 cost = 0.107631196\n",
      "Epoch: 0029 cost = 0.094216044\n",
      "Epoch: 0030 cost = 0.083795685\n",
      "Epoch: 0031 cost = 0.074988711\n",
      "Epoch: 0032 cost = 0.067743346\n",
      "Epoch: 0033 cost = 0.062180571\n",
      "Epoch: 0034 cost = 0.057425866\n",
      "Epoch: 0035 cost = 0.053762794\n",
      "Epoch: 0036 cost = 0.050789320\n",
      "Epoch: 0037 cost = 0.048533916\n",
      "Epoch: 0038 cost = 0.046516760\n",
      "Epoch: 0039 cost = 0.045345980\n",
      "Epoch: 0040 cost = 0.044019287\n",
      "Epoch: 0041 cost = 0.043142305\n",
      "Epoch: 0042 cost = 0.042504958\n",
      "Epoch: 0043 cost = 0.042066615\n",
      "Epoch: 0044 cost = 0.041563896\n",
      "Epoch: 0045 cost = 0.041433827\n",
      "Epoch: 0046 cost = 0.040810466\n",
      "Epoch: 0047 cost = 0.040709364\n",
      "Epoch: 0048 cost = 0.040539178\n",
      "Epoch: 0049 cost = 0.040490299\n",
      "Epoch: 0050 cost = 0.040301662\n",
      "Epoch: 0051 cost = 0.040136907\n",
      "Epoch: 0052 cost = 0.040167375\n",
      "Epoch: 0053 cost = 0.040134259\n",
      "Epoch: 0054 cost = 0.040043781\n",
      "Epoch: 0055 cost = 0.039857974\n",
      "Epoch: 0056 cost = 0.039861297\n",
      "Epoch: 0057 cost = 0.039837478\n",
      "Epoch: 0058 cost = 0.039911706\n",
      "Epoch: 0059 cost = 0.039788032\n",
      "Epoch: 0060 cost = 0.039811369\n",
      "Epoch: 0061 cost = 0.039791252\n",
      "Epoch: 0062 cost = 0.039690059\n",
      "Epoch: 0063 cost = 0.039756089\n",
      "Epoch: 0064 cost = 0.039660579\n",
      "Epoch: 0065 cost = 0.039802076\n",
      "Epoch: 0066 cost = 0.039647588\n",
      "Epoch: 0067 cost = 0.039679636\n",
      "Epoch: 0068 cost = 0.039712445\n",
      "Epoch: 0069 cost = 0.039671710\n",
      "Epoch: 0070 cost = 0.039590571\n",
      "Epoch: 0071 cost = 0.039885137\n",
      "Epoch: 0072 cost = 0.039482163\n",
      "Epoch: 0073 cost = 0.039744395\n",
      "Epoch: 0074 cost = 0.039585245\n",
      "Epoch: 0075 cost = 0.039618933\n",
      "Epoch: 0076 cost = 0.039608039\n",
      "Epoch: 0077 cost = 0.039600370\n",
      "Epoch: 0078 cost = 0.039561708\n",
      "Epoch: 0079 cost = 0.039740181\n",
      "Epoch: 0080 cost = 0.039589975\n",
      "Epoch: 0081 cost = 0.039447848\n",
      "Epoch: 0082 cost = 0.039529340\n",
      "Epoch: 0083 cost = 0.039665750\n",
      "Epoch: 0084 cost = 0.039505590\n",
      "Epoch: 0085 cost = 0.039697578\n",
      "Epoch: 0086 cost = 0.039558099\n",
      "Epoch: 0087 cost = 0.039575922\n",
      "Epoch: 0088 cost = 0.039598979\n",
      "Epoch: 0089 cost = 0.039486442\n",
      "Epoch: 0090 cost = 0.039616325\n",
      "Epoch: 0091 cost = 0.039697070\n",
      "Epoch: 0092 cost = 0.039511565\n",
      "Epoch: 0093 cost = 0.039417581\n",
      "Epoch: 0094 cost = 0.039665399\n",
      "Epoch: 0095 cost = 0.039625250\n",
      "Epoch: 0096 cost = 0.039744562\n",
      "Epoch: 0097 cost = 0.039436668\n",
      "Epoch: 0098 cost = 0.039552930\n",
      "Epoch: 0099 cost = 0.039563529\n",
      "Epoch: 0100 cost = 0.039721705\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'bool'>\n",
      "Accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# 정확도 확인하기\n",
    "# Test model and check accuracy\n",
    "pred = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "print (pred.dtype)\n",
    "accuracy = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "print('Accuracy (test) :', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
